{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation of Mined Product Reviews from Lululemon.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.max_colwidth = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'product_name',\n",
    "    'product_category',\n",
    "    'product_category_type',\n",
    "    'product_price',\n",
    "    'product_average_rating',\n",
    "    'customer_username',\n",
    "    'review_rating',\n",
    "    'customer_location',\n",
    "    'customer_athlete_type',\n",
    "    'customer_age_range',\n",
    "    'customer_body_type',\n",
    "    'review_likes',\n",
    "    'review_dislikes',\n",
    "    'review_fit',\n",
    "    'review_title',\n",
    "    'review_date',\n",
    "    'review_text',\n",
    "    'response_date',\n",
    "    'response_text',\n",
    "    'review_helpful_count',\n",
    "    'review_nothelpful_count'\n",
    "]\n",
    "df = pd.read_csv('mensrunning_lululemon.csv', names=cols)\n",
    "pd.set_option('display.max_columns', df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: 2418\n",
      "Features: 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_category</th>\n",
       "      <th>product_category_type</th>\n",
       "      <th>product_price</th>\n",
       "      <th>product_average_rating</th>\n",
       "      <th>customer_username</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>customer_location</th>\n",
       "      <th>customer_athlete_type</th>\n",
       "      <th>customer_age_range</th>\n",
       "      <th>customer_body_type</th>\n",
       "      <th>review_likes</th>\n",
       "      <th>review_dislikes</th>\n",
       "      <th>review_fit</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>response_date</th>\n",
       "      <th>response_text</th>\n",
       "      <th>review_helpful_count</th>\n",
       "      <th>review_nothelpful_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Metal Vent Tech Short Sleeve</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Short Sleeves</td>\n",
       "      <td>$68.00</td>\n",
       "      <td>2.9 out of 5</td>\n",
       "      <td>NYR26</td>\n",
       "      <td>5 out of 5</td>\n",
       "      <td>STAMFORD, CT</td>\n",
       "      <td>SWEATY GENERALIST</td>\n",
       "      <td>18-24</td>\n",
       "      <td>ATHLETIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The best tshirt</td>\n",
       "      <td>2018-10-12</td>\n",
       "      <td>These are the most comfortable T-shirts. Wish you guys would make more color...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Metal Vent Tech Short Sleeve</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Short Sleeves</td>\n",
       "      <td>$68.00</td>\n",
       "      <td>2.9 out of 5</td>\n",
       "      <td>MJB23</td>\n",
       "      <td>1 out of 5</td>\n",
       "      <td>CHICAGO, IL, USA</td>\n",
       "      <td>SWEATY GENERALIST</td>\n",
       "      <td>18-24</td>\n",
       "      <td>MUSCULAR</td>\n",
       "      <td>design</td>\n",
       "      <td>quality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very Poor Quality</td>\n",
       "      <td>2018-10-11</td>\n",
       "      <td>I purchased this Short Sleeve expecting it to be just like all the other one...</td>\n",
       "      <td>October 11, 2018</td>\n",
       "      <td>Dear mjb23,\\n\\nThanks for reaching out and providing this feedback for us. W...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Metal Vent Tech Short Sleeve</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Short Sleeves</td>\n",
       "      <td>$68.00</td>\n",
       "      <td>2.9 out of 5</td>\n",
       "      <td>JKD123</td>\n",
       "      <td>1 out of 5</td>\n",
       "      <td>CHICAGO, IL, USA</td>\n",
       "      <td>RUNNER</td>\n",
       "      <td>25-34</td>\n",
       "      <td>ATHLETIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stretch, comfort</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stretches When You Sweat</td>\n",
       "      <td>2018-10-08</td>\n",
       "      <td>I bought this shirt for my husband to run the Chicago Marathon. Upon startin...</td>\n",
       "      <td>October 9, 2018</td>\n",
       "      <td>Hi Jkd123,\\n\\nThanks for reaching out and providing this feedback for us. I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Metal Vent Tech Short Sleeve</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Short Sleeves</td>\n",
       "      <td>$68.00</td>\n",
       "      <td>2.9 out of 5</td>\n",
       "      <td>SLASH</td>\n",
       "      <td>5 out of 5</td>\n",
       "      <td>OVERLAND PARK, KS, USA</td>\n",
       "      <td>SWEATY GENERALIST</td>\n",
       "      <td>45-54</td>\n",
       "      <td>MUSCULAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love Lulu</td>\n",
       "      <td>2018-10-08</td>\n",
       "      <td>I have several shirts and shorts I have purchased from Lululemon. Hands down...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Metal Vent Tech Short Sleeve</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Short Sleeves</td>\n",
       "      <td>$68.00</td>\n",
       "      <td>2.9 out of 5</td>\n",
       "      <td>BRANDONM19</td>\n",
       "      <td>4 out of 5</td>\n",
       "      <td>HUTCHINSON, KS</td>\n",
       "      <td>SWEATY GENERALIST</td>\n",
       "      <td>18-24</td>\n",
       "      <td>ATHLETIC</td>\n",
       "      <td>sweat wicking material</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sweat wicking shirt</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>Great for workouts.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_name product_category product_category_type  \\\n",
       "0  Metal Vent Tech Short Sleeve             Tops         Short Sleeves   \n",
       "1  Metal Vent Tech Short Sleeve             Tops         Short Sleeves   \n",
       "2  Metal Vent Tech Short Sleeve             Tops         Short Sleeves   \n",
       "3  Metal Vent Tech Short Sleeve             Tops         Short Sleeves   \n",
       "4  Metal Vent Tech Short Sleeve             Tops         Short Sleeves   \n",
       "\n",
       "  product_price product_average_rating customer_username review_rating  \\\n",
       "0        $68.00           2.9 out of 5             NYR26    5 out of 5   \n",
       "1        $68.00           2.9 out of 5             MJB23    1 out of 5   \n",
       "2        $68.00           2.9 out of 5            JKD123    1 out of 5   \n",
       "3        $68.00           2.9 out of 5             SLASH    5 out of 5   \n",
       "4        $68.00           2.9 out of 5        BRANDONM19    4 out of 5   \n",
       "\n",
       "        customer_location customer_athlete_type customer_age_range  \\\n",
       "0            STAMFORD, CT     SWEATY GENERALIST              18-24   \n",
       "1        CHICAGO, IL, USA     SWEATY GENERALIST              18-24   \n",
       "2        CHICAGO, IL, USA                RUNNER              25-34   \n",
       "3  OVERLAND PARK, KS, USA     SWEATY GENERALIST              45-54   \n",
       "4          HUTCHINSON, KS     SWEATY GENERALIST              18-24   \n",
       "\n",
       "  customer_body_type            review_likes   review_dislikes review_fit  \\\n",
       "0           ATHLETIC                     NaN               NaN        NaN   \n",
       "1           MUSCULAR                  design           quality        NaN   \n",
       "2           ATHLETIC                     NaN  stretch, comfort        NaN   \n",
       "3           MUSCULAR                     NaN               NaN        NaN   \n",
       "4           ATHLETIC  sweat wicking material               NaN        NaN   \n",
       "\n",
       "               review_title review_date  \\\n",
       "0           The best tshirt  2018-10-12   \n",
       "1         Very Poor Quality  2018-10-11   \n",
       "2  Stretches When You Sweat  2018-10-08   \n",
       "3                 Love Lulu  2018-10-08   \n",
       "4       Sweat wicking shirt  2018-10-03   \n",
       "\n",
       "                                                                       review_text  \\\n",
       "0  These are the most comfortable T-shirts. Wish you guys would make more color...   \n",
       "1  I purchased this Short Sleeve expecting it to be just like all the other one...   \n",
       "2  I bought this shirt for my husband to run the Chicago Marathon. Upon startin...   \n",
       "3  I have several shirts and shorts I have purchased from Lululemon. Hands down...   \n",
       "4                                                              Great for workouts.   \n",
       "\n",
       "      response_date  \\\n",
       "0               NaN   \n",
       "1  October 11, 2018   \n",
       "2   October 9, 2018   \n",
       "3               NaN   \n",
       "4               NaN   \n",
       "\n",
       "                                                                     response_text  \\\n",
       "0                                                                              NaN   \n",
       "1  Dear mjb23,\\n\\nThanks for reaching out and providing this feedback for us. W...   \n",
       "2  Hi Jkd123,\\n\\nThanks for reaching out and providing this feedback for us. I ...   \n",
       "3                                                                              NaN   \n",
       "4                                                                              NaN   \n",
       "\n",
       "   review_helpful_count  review_nothelpful_count  \n",
       "0                     0                        0  \n",
       "1                     0                        0  \n",
       "2                     0                        0  \n",
       "3                     0                        0  \n",
       "4                     0                        0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Observations: {}'.format(df.shape[0]))\n",
    "print('Features: {}'.format(df.shape[1]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime objects # \n",
    "df['review_date'] = pd.to_datetime(df['review_date'], infer_datetime_format=True)\n",
    "df['response_date'] = pd.to_datetime(df['response_date'], infer_datetime_format=True)\n",
    "\n",
    "# Strip ratings\n",
    "df['review_rating'] = df['review_rating'].apply(lambda x: re.split(' ', x)[0]).map(float)\n",
    "df['product_average_rating'] = df['product_average_rating'].apply(lambda x: re.split(' ', x)[0]).map(float)\n",
    "\n",
    "# Strip dollar signs\n",
    "df['product_price'] = df['product_price'].str.slice(1).astype(float)\n",
    "\n",
    "# Clean product names\n",
    "df['product_name'] = df['product_name'].str.replace('\\n', ' ')\n",
    "\n",
    "# Clean review and response text\n",
    "df['review_text'] = df['review_text'].str.replace('\\n', ' ', )\n",
    "df['response_text'] = df['response_text'].str.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing product_name and product_type mislabellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find products with different product types \n",
    "\n",
    "grp_prod = df.groupby(['product_name', 'product_category_type'])['product_category_type'].describe().reset_index()\n",
    "mismatched = grp_prod[grp_prod.duplicated(subset='product_name', keep=False)][['product_name', 'product_category_type']]\n",
    "mismatched = mismatched['product_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace mismatched productType with 'Hoodies'\n",
    "\n",
    "X = df[ (df['product_name']==mismatched[0]) | (df['product_name']==mismatched[1]) ].index\n",
    "df.loc[X, 'product_category_type'] = 'Hoodies'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Duplicate Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some products have different urls with the same reviews to them if there are styles of the product on sale\n",
    "# There are also duplicates when a product is updated and reviews stay the same\n",
    "\n",
    "df = df[-df.duplicated(subset=['review_text','customer_username'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_location         344\n",
       "customer_athlete_type     346\n",
       "customer_age_range        311\n",
       "customer_body_type        312\n",
       "review_likes              773\n",
       "review_dislikes           939\n",
       "review_fit               1548\n",
       "review_title                8\n",
       "response_date            1190\n",
       "response_text            1190\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[df.isnull().any()]].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values: False\n"
     ]
    }
   ],
   "source": [
    "# Replace missing values where a customer/representative wouldn't have responded to a feature and fill with 'No Response'\n",
    "df.fillna('No Response', inplace=True)\n",
    "print('Missing Values: {}'.format(any(df.isnull().any())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create columns for length of each review\n",
    "df['review_length'] = df['review_text'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary column for response (1) or not (0)\n",
    "df['review_response'] = np.where(df['response_text'] == 'No Response', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_category</th>\n",
       "      <th>product_category_type</th>\n",
       "      <th>product_price</th>\n",
       "      <th>product_average_rating</th>\n",
       "      <th>customer_username</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>customer_location</th>\n",
       "      <th>customer_athlete_type</th>\n",
       "      <th>customer_age_range</th>\n",
       "      <th>...</th>\n",
       "      <th>review_fit</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>response_date</th>\n",
       "      <th>response_text</th>\n",
       "      <th>review_helpful_count</th>\n",
       "      <th>review_nothelpful_count</th>\n",
       "      <th>review_length</th>\n",
       "      <th>review_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Metal Vent Tech Short Sleeve</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Short Sleeves</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>NYR26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>STAMFORD, CT</td>\n",
       "      <td>SWEATY GENERALIST</td>\n",
       "      <td>18-24</td>\n",
       "      <td>...</td>\n",
       "      <td>No Response</td>\n",
       "      <td>The best tshirt</td>\n",
       "      <td>2018-10-12</td>\n",
       "      <td>These are the most comfortable T-shirts. Wish you guys would make more color...</td>\n",
       "      <td>No Response</td>\n",
       "      <td>No Response</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Metal Vent Tech Short Sleeve</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Short Sleeves</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>MJB23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CHICAGO, IL, USA</td>\n",
       "      <td>SWEATY GENERALIST</td>\n",
       "      <td>18-24</td>\n",
       "      <td>...</td>\n",
       "      <td>No Response</td>\n",
       "      <td>Very Poor Quality</td>\n",
       "      <td>2018-10-11</td>\n",
       "      <td>I purchased this Short Sleeve expecting it to be just like all the other one...</td>\n",
       "      <td>2018-10-11 00:00:00</td>\n",
       "      <td>Dear mjb23,  Thanks for reaching out and providing this feedback for us. We ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>567</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Metal Vent Tech Short Sleeve</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Short Sleeves</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>JKD123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CHICAGO, IL, USA</td>\n",
       "      <td>RUNNER</td>\n",
       "      <td>25-34</td>\n",
       "      <td>...</td>\n",
       "      <td>No Response</td>\n",
       "      <td>Stretches When You Sweat</td>\n",
       "      <td>2018-10-08</td>\n",
       "      <td>I bought this shirt for my husband to run the Chicago Marathon. Upon startin...</td>\n",
       "      <td>2018-10-09 00:00:00</td>\n",
       "      <td>Hi Jkd123,  Thanks for reaching out and providing this feedback for us. I co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>269</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Metal Vent Tech Short Sleeve</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Short Sleeves</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>SLASH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>OVERLAND PARK, KS, USA</td>\n",
       "      <td>SWEATY GENERALIST</td>\n",
       "      <td>45-54</td>\n",
       "      <td>...</td>\n",
       "      <td>No Response</td>\n",
       "      <td>Love Lulu</td>\n",
       "      <td>2018-10-08</td>\n",
       "      <td>I have several shirts and shorts I have purchased from Lululemon. Hands down...</td>\n",
       "      <td>No Response</td>\n",
       "      <td>No Response</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Metal Vent Tech Short Sleeve</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Short Sleeves</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>BRANDONM19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HUTCHINSON, KS</td>\n",
       "      <td>SWEATY GENERALIST</td>\n",
       "      <td>18-24</td>\n",
       "      <td>...</td>\n",
       "      <td>No Response</td>\n",
       "      <td>Sweat wicking shirt</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>Great for workouts.</td>\n",
       "      <td>No Response</td>\n",
       "      <td>No Response</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_name product_category product_category_type  \\\n",
       "0  Metal Vent Tech Short Sleeve             Tops         Short Sleeves   \n",
       "1  Metal Vent Tech Short Sleeve             Tops         Short Sleeves   \n",
       "2  Metal Vent Tech Short Sleeve             Tops         Short Sleeves   \n",
       "3  Metal Vent Tech Short Sleeve             Tops         Short Sleeves   \n",
       "4  Metal Vent Tech Short Sleeve             Tops         Short Sleeves   \n",
       "\n",
       "   product_price  product_average_rating customer_username  review_rating  \\\n",
       "0           68.0                     2.9             NYR26            5.0   \n",
       "1           68.0                     2.9             MJB23            1.0   \n",
       "2           68.0                     2.9            JKD123            1.0   \n",
       "3           68.0                     2.9             SLASH            5.0   \n",
       "4           68.0                     2.9        BRANDONM19            4.0   \n",
       "\n",
       "        customer_location customer_athlete_type customer_age_range  \\\n",
       "0            STAMFORD, CT     SWEATY GENERALIST              18-24   \n",
       "1        CHICAGO, IL, USA     SWEATY GENERALIST              18-24   \n",
       "2        CHICAGO, IL, USA                RUNNER              25-34   \n",
       "3  OVERLAND PARK, KS, USA     SWEATY GENERALIST              45-54   \n",
       "4          HUTCHINSON, KS     SWEATY GENERALIST              18-24   \n",
       "\n",
       "        ...          review_fit              review_title review_date  \\\n",
       "0       ...         No Response           The best tshirt  2018-10-12   \n",
       "1       ...         No Response         Very Poor Quality  2018-10-11   \n",
       "2       ...         No Response  Stretches When You Sweat  2018-10-08   \n",
       "3       ...         No Response                 Love Lulu  2018-10-08   \n",
       "4       ...         No Response       Sweat wicking shirt  2018-10-03   \n",
       "\n",
       "                                                                       review_text  \\\n",
       "0  These are the most comfortable T-shirts. Wish you guys would make more color...   \n",
       "1  I purchased this Short Sleeve expecting it to be just like all the other one...   \n",
       "2  I bought this shirt for my husband to run the Chicago Marathon. Upon startin...   \n",
       "3  I have several shirts and shorts I have purchased from Lululemon. Hands down...   \n",
       "4                                                              Great for workouts.   \n",
       "\n",
       "         response_date  \\\n",
       "0          No Response   \n",
       "1  2018-10-11 00:00:00   \n",
       "2  2018-10-09 00:00:00   \n",
       "3          No Response   \n",
       "4          No Response   \n",
       "\n",
       "                                                                     response_text  \\\n",
       "0                                                                      No Response   \n",
       "1  Dear mjb23,  Thanks for reaching out and providing this feedback for us. We ...   \n",
       "2  Hi Jkd123,  Thanks for reaching out and providing this feedback for us. I co...   \n",
       "3                                                                      No Response   \n",
       "4                                                                      No Response   \n",
       "\n",
       "  review_helpful_count review_nothelpful_count review_length  review_response  \n",
       "0                    0                       0           150                0  \n",
       "1                    0                       0           567                1  \n",
       "2                    0                       0           269                1  \n",
       "3                    0                       0           170                0  \n",
       "4                    0                       0            19                0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1859, 23)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have left 1859 unique product reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a customer country column\n",
    "- locations are either:\n",
    "    - city/town, state(abbv)\n",
    "    - city, province/territory\n",
    "    - state(abbv)\n",
    "    - city/town\n",
    "    - town\n",
    "- we can narrow this down by separating locations that:\n",
    "    - 1) have a comma\n",
    "    - 2) are just one string\n",
    "        - one string that with length two that is either a:\n",
    "            - US state abbv, or\n",
    "            - Canadian providence/territory\n",
    "            - some other location not in the US or Canada\n",
    "        - one string that is either a:\n",
    "            - city/town name\n",
    "            - a US state\n",
    "            - a Canadian providence/territory\n",
    "            - some other location not in the US or Canada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty customer_country series\n",
    "df['customer_country'] = pd.Series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values: 1247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1603          ATLANTA, GA, USA\n",
       "1776         NEW YORK, NY, USA\n",
       "883          LEHIGH VALLEY, PA\n",
       "1381         NEW YORK, NY, USA\n",
       "1503        KNOXVILLE, TN, USA\n",
       "230         ST. LOUIS, MO, USA\n",
       "1803            SUCCASUNNA, NJ\n",
       "810            NAPLES, FL, USA\n",
       "658            CALIFORNIA, USA\n",
       "942              ANN ARBOR, MI\n",
       "423       PANAMA CITY, FL, USA\n",
       "1523      SANTA CLARA, CA, USA\n",
       "1564    KENORA, ON P0V, CANADA\n",
       "280           HOUSTON, TX, USA\n",
       "1120    SAN FRANCISCO, CA, USA\n",
       "1363         NEWPORT BEACH, CA\n",
       "243           BURBANK, CA, USA\n",
       "128         KNOXVILLE, TN, USA\n",
       "565           CHICAGO, IL, USA\n",
       "1624            MIAMI, FL, USA\n",
       "Name: customer_location, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Locations with a comma\n",
    "locations = df[df['customer_location'] != 'No Response']['customer_location']\n",
    "commas = locations[locations.str.contains(', ')]\n",
    "print('Values: {}'.format(len(commas)))\n",
    "commas.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location country\n",
       "0       CT     NaN\n",
       "1      USA     NaN\n",
       "2      USA     NaN\n",
       "3      USA     NaN\n",
       "4       KS     NaN"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_countries_df = pd.DataFrame(columns = ['location', 'country'], index=commas.index)\n",
    "temp_countries_df['location'] = [loc[-1] for loc in commas.str.split(', ')]\n",
    "temp_countries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# US States\n",
    "states = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AS': 'American Samoa',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DC': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'GU': 'Guam',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MP': 'Northern Mariana Islands',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NA': 'National',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'PR': 'Puerto Rico',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "}\n",
    "\n",
    "# Provinces/Territories in Canada\n",
    "provs_terrs = {\n",
    "    'AB': 'Alberta',\n",
    "    'BC': 'British Columbia',\n",
    "    'MB': 'Manitoba',\n",
    "    'NB': 'New Brunswick',\n",
    "    'NL': 'Newfoundland and Labrador',\n",
    "    'NT': 'Northwest Territories',\n",
    "    'NS': 'Nova Scotia',\n",
    "    'NU': 'Nunavut',\n",
    "    'ON': 'Ontario',\n",
    "    'PE': 'Prince Edward Island',\n",
    "    'QC': 'Quebec',\n",
    "    'SK': 'Saskatchewan',\n",
    "    'YT': 'Yukon'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa = ['United States', 'United States of America', 'US', 'USA', 'UNITED STATES']\n",
    "usa_condition = [i in usa for i in temp_countries_df['location']] # locations that are in the USA\n",
    "\n",
    "usa_states_abbvs = states.keys()\n",
    "usa_state_abbvs_condition = [i in usa_states_abbvs for i in temp_countries_df['location']] # locations that are state abbreviations in the USA\n",
    "\n",
    "usa_states = [state.upper() for state in states.values()]\n",
    "usa_state_condition = [i in usa_states for i in temp_countries_df['location']] # locations that are states in USA\n",
    "\n",
    "canada = ['Canada', 'CANADA']\n",
    "canada_condition = [i in canada for i in temp_countries_df['location']] # locations that are in Canada\n",
    "\n",
    "canada_provs_terrs_abbvs = provs_terrs.keys()\n",
    "canada_prov_terr_abbvs_condition = [i in canada_provs_terrs_abbvs for i in temp_countries_df['location']] # locations that are province/territory abbreviations in Canada\n",
    "\n",
    "canada_provs_terrs = [prov_terr.upper() for prov_terr in provs_terrs.values()]\n",
    "canada_prov_terr_condition = [i in canada_provs_terrs for i in temp_countries_df['location']] # locations that are provinces/territories in Canada\n",
    "\n",
    "\n",
    "australia = ['AUS', 'Australia', 'AUSTRALIA']\n",
    "australia_condition = [i in australia for i in temp_countries_df['location']] # locations that are in Australia\n",
    "\n",
    "mexico = ['MEXICO', 'MEX']\n",
    "mexico_condition = [i in mexico for i in temp_countries_df['location']] # locations that are in Mexico\n",
    "\n",
    "uk = ['United Kingdom', 'UNITED KINGDOM', 'UK']\n",
    "uk_condition = [i in uk for i in temp_countries_df['location']] # locations that are in the UK\n",
    "\n",
    "philippines = ['Philippines', 'PHILIPPINES', 'PHL', 'PH']\n",
    "philippines_condition = [i in philippines for i in temp_countries_df['location']] # locations that are in the Phillipines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_countries_df.loc[usa_condition, 'country'] = ['USA' for i in temp_countries_df['location'] if i in usa]\n",
    "temp_countries_df.loc[usa_state_abbvs_condition, 'country'] = ['USA' for i in temp_countries_df['location'] if i in usa_states_abbvs]\n",
    "temp_countries_df.loc[usa_state_condition, 'country'] = ['USA' for i in temp_countries_df['location'] if i in usa_states]\n",
    "\n",
    "temp_countries_df.loc[canada_condition, 'country'] = ['Canada' for i in temp_countries_df['location'] if i in canada]\n",
    "temp_countries_df.loc[canada_prov_terr_abbvs_condition, 'country'] = ['Canada' for i in temp_countries_df['location'] if i in canada_provs_terrs_abbvs]\n",
    "temp_countries_df.loc[canada_prov_terr_condition, 'country'] = ['Canada' for i in temp_countries_df['location'] if i in canada_provs_terrs]\n",
    "\n",
    "temp_countries_df.loc[australia_condition, 'country'] = ['Australia' for i in temp_countries_df['location'] if i in australia]\n",
    "\n",
    "temp_countries_df.loc[mexico_condition, 'country'] = ['Mexico' for i in temp_countries_df['location'] if i in mexico]\n",
    "\n",
    "temp_countries_df.loc[uk_condition, 'country'] = ['UK' for i in temp_countries_df['location'] if i in uk]\n",
    "\n",
    "temp_countries_df.loc[philippines_condition, 'country'] = ['Philippines' for i in temp_countries_df['location'] if i in philippines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BC / LOS ANGELES', 'ONTATIO', 'EARTH',\n",
       "       'BUT TRAVELING IN CENTRAL AND SOUTH AMERICA', 'CA USA'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_countries_df.loc[temp_countries_df['country'].isnull(), 'location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359                               BC / LOS ANGELES\n",
       "436                                        ONTATIO\n",
       "734                                          EARTH\n",
       "951     BUT TRAVELING IN CENTRAL AND SOUTH AMERICA\n",
       "1323                                        CA USA\n",
       "Name: location, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually enter what is leftover ... can't win them all\n",
    "temp_countries_df.loc[temp_countries_df['country'].isnull(), 'location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_countries_df.loc[359]['country'] = 'Canada'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[436, 'customer_location'] = 'LONDON, ONTARIO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_countries_df.loc[436]['country'] = 'Canada'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_countries_df.loc[734, 'country'] = 'USA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other products bought: False\n"
     ]
    }
   ],
   "source": [
    "print('Other products bought: {}'.format(df[df['customer_username'] == df.loc[951, 'customer_username']].shape[0] > 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_countries_df.loc[951, 'country'] = 'Canada'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_countries_df.loc[1323, 'country'] = 'USA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location    0\n",
       "country     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_countries_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['customer_country'] = temp_countries_df['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values: 268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1339           ARIZONA\n",
       "1519          GRAND RA\n",
       "697            RALEIGH\n",
       "391                NYC\n",
       "749          SINGAPORE\n",
       "1300        SEATTLE WA\n",
       "1713          NEW YORK\n",
       "1529                NH\n",
       "1487         SINGAPORE\n",
       "1678     MASSACHUSETTS\n",
       "1854           CALGARY\n",
       "279                NYC\n",
       "79              DALLAS\n",
       "915            CHICAGO\n",
       "1473          SCOTLAND\n",
       "345           VIRGINIA\n",
       "945           VICTORIA\n",
       "332            GEORGIA\n",
       "1841         LAS VEGAS\n",
       "317     SAINT LOUIS MO\n",
       "Name: customer_location, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Locations without a comma\n",
    "no_commas = locations[-locations.str.contains(', ')]\n",
    "print('Values: {}'.format(len(no_commas)))\n",
    "no_commas.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>split_location</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SAN FRANCISCO</td>\n",
       "      <td>FRANCISCO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>WISCONSIN</td>\n",
       "      <td>WISCONSIN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DENVER COLORADO</td>\n",
       "      <td>COLORADO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NJ</td>\n",
       "      <td>NJ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           location split_location country\n",
       "12    SAN FRANCISCO      FRANCISCO     NaN\n",
       "20        WISCONSIN      WISCONSIN     NaN\n",
       "27  DENVER COLORADO       COLORADO     NaN\n",
       "30               NJ             NJ     NaN\n",
       "40     PHILADELPHIA   PHILADELPHIA     NaN"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a new temp_countries_df to handle these locations\n",
    "temp_countries_df = pd.DataFrame(columns = [ 'location',\n",
    "                                            'split_location',\n",
    "                                            'country'], \n",
    "                                 index=no_commas.index)\n",
    "temp_countries_df['location'] = no_commas\n",
    "temp_countries_df['split_location'] = [loc[-1] for loc in no_commas.str.split(' ')]\n",
    "temp_countries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_location_condition(country_list):\n",
    "    return [i in country_list for i in temp_countries_df['split_location']]\n",
    "\n",
    "usa_condition = check_location_condition(usa)\n",
    "usa_state_abbvs_condition = check_location_condition(usa_states_abbvs)\n",
    "usa_state_condition = check_location_condition(usa_states)\n",
    "\n",
    "canada_condition = check_location_condition(canada)\n",
    "canada_prov_terr_condition = check_location_condition(canada_provs_terrs)\n",
    "canada_prov_terr_abbvs_condition = check_location_condition(canada_provs_terrs_abbvs)\n",
    "\n",
    "australia_condition = check_location_condition(australia)\n",
    "\n",
    "mexico_condition = check_location_condition(mexico)\n",
    "\n",
    "uk_condition = check_location_condition(uk)\n",
    "\n",
    "philippines_condition = check_location_condition(philippines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_country(condition, country, country_list):\n",
    "    temp_countries_df.loc[condition, 'country'] = [country for i in temp_countries_df['split_location'] if i in country_list]\n",
    "    return temp_countries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_countries_df = create_country(usa_condition, 'USA', usa)\n",
    "temp_countries_df = create_country(usa_state_abbvs_condition, 'USA', usa_states_abbvs)\n",
    "temp_countries_df = create_country(usa_state_condition, 'USA', usa_states)\n",
    "temp_countries_df = create_country(canada_condition, 'Canada', canada)\n",
    "temp_countries_df = create_country(canada_prov_terr_condition, 'Canada', canada_provs_terrs)\n",
    "temp_countries_df = create_country(canada_prov_terr_abbvs_condition, 'Canada', canada_provs_terrs_abbvs)\n",
    "temp_countries_df = create_country(australia_condition, 'Australia', australia)\n",
    "temp_countries_df = create_country(mexico_condition, 'Mexico', mexico)\n",
    "temp_countries_df = create_country(uk_condition, 'UK', uk)\n",
    "temp_countries_df = create_country(philippines_condition, 'Philippines', philippines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SAN FRANCISCO', 'PHILADELPHIA', 'MIAMI', 'DALLAS', 'CHICAGO',\n",
       "       'DENVER', 'NEW YORK', 'BOSTON', 'SAN DIEGO', 'OTTAWA', 'HOUSTON',\n",
       "       'DETROIT', 'SCOTTSDALE', 'ST. LOUIS', 'SPOKANE', 'NYC', 'PHOENIX',\n",
       "       'UNITED STATES', 'ONTAIRO', 'LOS ANGELES', 'KANSAS CITY',\n",
       "       'MANHATTAN', 'ONLINE', 'SEATTLE', 'NEW JERSEY', 'TORONTO',\n",
       "       'WASHINGTON D.C.', 'SOUTH EAST ASIA', 'CLEVELAND', 'NOCAL',\n",
       "       'SINGAPORE', 'NORTH CAROLINA', 'TAIWAN', 'MEXICO CITY', 'RALEIGH',\n",
       "       'LONG BEACH', 'MINNEAPOLIS', 'AUSTIN', 'PACIFIC NW',\n",
       "       'RIVERHEAD NEW YORK', 'AUSTIB', 'VICTORIA', 'VANCOUVER',\n",
       "       'SACRAMENTO', 'BAY AREA', 'SOUTH KOREA', 'NANAIMO', 'DFW',\n",
       "       'BOSTON,MA', 'WASHINGTON STATE', 'OC', 'CALGARY',\n",
       "       'LAC DU BONNET,MB', 'ALL OVER', 'NORTHEAST', 'HONG KONG',\n",
       "       'WINNIPEG', 'CINCINNATI,OHIO', 'NEW BRUNSWICK', 'LONG ISLAND',\n",
       "       'BROOKLYN', 'ATLANTA', 'ALL OVER THE COUNTRY', 'SCOTLAND',\n",
       "       'NEWFOUNDLAND', 'GRAND RA', 'SALT LAKE CITY', 'FORT MCMURRAY',\n",
       "       'NEW YOR', 'SANTA BARBARA', 'HALIFAX', 'UPSTATE',\n",
       "       'SUBURBAN DETROIT', 'SOCAL', 'CHARLOTTE', 'LAS VEGAS'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine original locations\n",
    "leftovers = temp_countries_df[temp_countries_df['country'].isnull()]['location']\n",
    "leftovers.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_condition(location):\n",
    "    return [loc == location for loc in temp_countries_df['location']]\n",
    "def create_manual_country(condition, country):\n",
    "    temp_countries_df.loc[condition, 'country'] = country\n",
    "    return temp_countries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_us = [\n",
    "    'OTTAWA',\n",
    "    'ONTAIRO',\n",
    "    'TORONTO',\n",
    "    'SOUTH EAST ASIA',\n",
    "    'SINGAPORE',\n",
    "    'TAIWAN',\n",
    "    'MEXICO CITY',\n",
    "    'VICTORIA',\n",
    "    'VANCOUVER',\n",
    "    'SOUTH KOREA',\n",
    "    'NANAIMO',\n",
    "    'CALGARY',\n",
    "    'LAC DU BONNET,MB',\n",
    "    'HONG KONG',\n",
    "    'WINNIPEG',\n",
    "    'SCOTLAND',\n",
    "    'NEWFOUNDLAND',\n",
    "    'FORT MCMURRAY',\n",
    "    'HALIFAX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_places = [place for place in leftovers.unique() if place not in not_us]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in us_places:\n",
    "    create_manual_country(manual_condition(i), 'USA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "canada_places = [\n",
    "    'OTTAWA',\n",
    "    'ONTAIRO',\n",
    "    'TORONTO',\n",
    "    'VICTORIA',\n",
    "    'VANCOUVER',\n",
    "    'NANAIMO',\n",
    "    'CALGARY',\n",
    "    'LAC DU BONNET,MB',\n",
    "    'WINNIPEG',\n",
    "    'NEWFOUNDLAND',\n",
    "    'FORT MCMURRAY'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in canada_places:\n",
    "    create_manual_country(manual_condition(i), 'Canada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>split_location</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>SOUTH EAST ASIA</td>\n",
       "      <td>ASIA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>SINGAPORE</td>\n",
       "      <td>SINGAPORE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>TAIWAN</td>\n",
       "      <td>TAIWAN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>MEXICO CITY</td>\n",
       "      <td>CITY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>SINGAPORE</td>\n",
       "      <td>SINGAPORE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>SOUTH KOREA</td>\n",
       "      <td>KOREA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>HONG KONG</td>\n",
       "      <td>KONG</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>SCOTLAND</td>\n",
       "      <td>SCOTLAND</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>SINGAPORE</td>\n",
       "      <td>SINGAPORE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>SOUTH EAST ASIA</td>\n",
       "      <td>ASIA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>HALIFAX</td>\n",
       "      <td>HALIFAX</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>TAIWAN</td>\n",
       "      <td>TAIWAN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             location split_location country\n",
       "487   SOUTH EAST ASIA           ASIA     NaN\n",
       "559         SINGAPORE      SINGAPORE     NaN\n",
       "650            TAIWAN         TAIWAN     NaN\n",
       "661       MEXICO CITY           CITY     NaN\n",
       "749         SINGAPORE      SINGAPORE     NaN\n",
       "1000      SOUTH KOREA          KOREA     NaN\n",
       "1278        HONG KONG           KONG     NaN\n",
       "1473         SCOTLAND       SCOTLAND     NaN\n",
       "1487        SINGAPORE      SINGAPORE     NaN\n",
       "1626  SOUTH EAST ASIA           ASIA     NaN\n",
       "1771          HALIFAX        HALIFAX     NaN\n",
       "1809           TAIWAN         TAIWAN     NaN"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_countries_df[temp_countries_df['country'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>split_location</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SAN FRANCISCO</td>\n",
       "      <td>FRANCISCO</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>WISCONSIN</td>\n",
       "      <td>WISCONSIN</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DENVER COLORADO</td>\n",
       "      <td>COLORADO</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NJ</td>\n",
       "      <td>NJ</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>MIAMI</td>\n",
       "      <td>MIAMI</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>VERMONT</td>\n",
       "      <td>VERMONT</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>DALLAS</td>\n",
       "      <td>DALLAS</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>DENVER</td>\n",
       "      <td>DENVER</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>WA</td>\n",
       "      <td>WA</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>ONTARIO</td>\n",
       "      <td>ONTARIO</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>MICHIGAN</td>\n",
       "      <td>MICHIGAN</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>YORK</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>NORTHERN CALIFORNIA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>BOSTON</td>\n",
       "      <td>BOSTON</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>SAN DIEGO</td>\n",
       "      <td>DIEGO</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>CT</td>\n",
       "      <td>CT</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>HALIFAX NS</td>\n",
       "      <td>NS</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>OTTAWA</td>\n",
       "      <td>OTTAWA</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>SAN FRANCISCO</td>\n",
       "      <td>FRANCISCO</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>MIDWEST USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>WI</td>\n",
       "      <td>WI</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>VA</td>\n",
       "      <td>VA</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>YORK</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718</th>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>ANGELES</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>MICHIGAN</td>\n",
       "      <td>MICHIGAN</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>VANCOUVER</td>\n",
       "      <td>VANCOUVER</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>NJ</td>\n",
       "      <td>NJ</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>NEWFOUNDLAND</td>\n",
       "      <td>NEWFOUNDLAND</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>HALIFAX</td>\n",
       "      <td>HALIFAX</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>CALGARY</td>\n",
       "      <td>CALGARY</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>UPSTATE</td>\n",
       "      <td>UPSTATE</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>RI</td>\n",
       "      <td>RI</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>COLORADO</td>\n",
       "      <td>COLORADO</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>SUBURBAN DETROIT</td>\n",
       "      <td>DETROIT</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>AB</td>\n",
       "      <td>AB</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>WV</td>\n",
       "      <td>WV</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>FL</td>\n",
       "      <td>FL</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>SOCAL</td>\n",
       "      <td>SOCAL</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>TAIWAN</td>\n",
       "      <td>TAIWAN</td>\n",
       "      <td>Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>MINNESOTA</td>\n",
       "      <td>MINNESOTA</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>CHARLOTTE</td>\n",
       "      <td>CHARLOTTE</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>LAS VEGAS</td>\n",
       "      <td>VEGAS</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>RESIDE AND TEACH IN LA. FROM PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>KANSAS</td>\n",
       "      <td>KANSAS</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>STATES</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>CALGARY</td>\n",
       "      <td>CALGARY</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>OH</td>\n",
       "      <td>OH</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             location split_location country\n",
       "12                      SAN FRANCISCO      FRANCISCO     USA\n",
       "20                          WISCONSIN      WISCONSIN     USA\n",
       "27                    DENVER COLORADO       COLORADO     USA\n",
       "30                                 NJ             NJ     USA\n",
       "40                       PHILADELPHIA   PHILADELPHIA     USA\n",
       "51                              MIAMI          MIAMI     USA\n",
       "53                                 US             US     USA\n",
       "56                            VERMONT        VERMONT     USA\n",
       "68                         CALIFORNIA     CALIFORNIA     USA\n",
       "78                                 PA             PA     USA\n",
       "79                             DALLAS         DALLAS     USA\n",
       "81                            GEORGIA        GEORGIA     USA\n",
       "82                            CHICAGO        CHICAGO     USA\n",
       "83                            FLORIDA        FLORIDA     USA\n",
       "85                             DENVER         DENVER     USA\n",
       "86                                 WA             WA     USA\n",
       "88                            ONTARIO        ONTARIO  Canada\n",
       "91                           MICHIGAN       MICHIGAN     USA\n",
       "92                           NEW YORK           YORK     USA\n",
       "102               NORTHERN CALIFORNIA     CALIFORNIA     USA\n",
       "106                            BOSTON         BOSTON     USA\n",
       "115                                NC             NC     USA\n",
       "124                         SAN DIEGO          DIEGO     USA\n",
       "125                                CT             CT     USA\n",
       "136                        HALIFAX NS             NS  Canada\n",
       "139                            OTTAWA         OTTAWA  Canada\n",
       "149                     SAN FRANCISCO      FRANCISCO     USA\n",
       "155                       MIDWEST USA            USA     USA\n",
       "164                                WI             WI     USA\n",
       "173                               USA            USA     USA\n",
       "...                               ...            ...     ...\n",
       "1686                               VA             VA     USA\n",
       "1696                          CHICAGO        CHICAGO     USA\n",
       "1707                               NY             NY     USA\n",
       "1713                         NEW YORK           YORK     USA\n",
       "1718                      LOS ANGELES        ANGELES     USA\n",
       "1750                         MICHIGAN       MICHIGAN     USA\n",
       "1753                        VANCOUVER      VANCOUVER  Canada\n",
       "1761                               NJ             NJ     USA\n",
       "1762                          HOUSTON        HOUSTON     USA\n",
       "1770                     NEWFOUNDLAND   NEWFOUNDLAND  Canada\n",
       "1771                          HALIFAX        HALIFAX      UK\n",
       "1772                          CALGARY        CALGARY  Canada\n",
       "1773                          UPSTATE        UPSTATE     USA\n",
       "1774                               RI             RI     USA\n",
       "1780                         COLORADO       COLORADO     USA\n",
       "1782                 SUBURBAN DETROIT        DETROIT     USA\n",
       "1785                               AB             AB  Canada\n",
       "1801                               WV             WV     USA\n",
       "1802                               FL             FL     USA\n",
       "1807                            SOCAL          SOCAL     USA\n",
       "1809                           TAIWAN         TAIWAN  Taiwan\n",
       "1811                        MINNESOTA      MINNESOTA     USA\n",
       "1812                        CHARLOTTE      CHARLOTTE     USA\n",
       "1821                          ATLANTA        ATLANTA     USA\n",
       "1841                        LAS VEGAS          VEGAS     USA\n",
       "1845  RESIDE AND TEACH IN LA. FROM PA             PA     USA\n",
       "1851                           KANSAS         KANSAS     USA\n",
       "1852                    UNITED STATES         STATES     USA\n",
       "1854                          CALGARY        CALGARY  Canada\n",
       "1855                               OH             OH     USA\n",
       "\n",
       "[268 rows x 3 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_manual_country(manual_condition('SOUTH EAST ASIA'), 'South East Asia')\n",
    "create_manual_country(manual_condition('SINGAPORE'), 'Singapore')\n",
    "create_manual_country(manual_condition('TAIWAN'), 'Taiwan')\n",
    "create_manual_country(manual_condition('MEXICO CITY'), 'Mexico')\n",
    "create_manual_country(manual_condition('SOUTH KOREA'), 'South Korea')\n",
    "create_manual_country(manual_condition('HONG KONG'), 'Hong Kong')\n",
    "create_manual_country(manual_condition('SCOTLAND'), 'Scotland')\n",
    "create_manual_country(manual_condition('HALIFAX'), 'UK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[temp_countries_df.index, 'customer_country'] = temp_countries_df['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['customer_country'].fillna('No Response', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(df.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_mensrunning_lululemon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_category</th>\n",
       "      <th>product_category_type</th>\n",
       "      <th>product_price</th>\n",
       "      <th>product_average_rating</th>\n",
       "      <th>customer_username</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>customer_location</th>\n",
       "      <th>customer_athlete_type</th>\n",
       "      <th>customer_age_range</th>\n",
       "      <th>...</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>response_date</th>\n",
       "      <th>response_text</th>\n",
       "      <th>review_helpful_count</th>\n",
       "      <th>review_nothelpful_count</th>\n",
       "      <th>review_length</th>\n",
       "      <th>review_response</th>\n",
       "      <th>customer_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Metal Vent Tech Short Sleeve</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Short Sleeves</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>NYR26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>STAMFORD, CT</td>\n",
       "      <td>SWEATY GENERALIST</td>\n",
       "      <td>18-24</td>\n",
       "      <td>...</td>\n",
       "      <td>The best tshirt</td>\n",
       "      <td>2018-10-12</td>\n",
       "      <td>These are the most comfortable T-shirts. Wish you guys would make more color...</td>\n",
       "      <td>No Response</td>\n",
       "      <td>No Response</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Metal Vent Tech Short Sleeve</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Short Sleeves</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>MJB23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CHICAGO, IL, USA</td>\n",
       "      <td>SWEATY GENERALIST</td>\n",
       "      <td>18-24</td>\n",
       "      <td>...</td>\n",
       "      <td>Very Poor Quality</td>\n",
       "      <td>2018-10-11</td>\n",
       "      <td>I purchased this Short Sleeve expecting it to be just like all the other one...</td>\n",
       "      <td>2018-10-11 00:00:00</td>\n",
       "      <td>Dear mjb23,  Thanks for reaching out and providing this feedback for us. We ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>567</td>\n",
       "      <td>1</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Metal Vent Tech Short Sleeve</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Short Sleeves</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>JKD123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CHICAGO, IL, USA</td>\n",
       "      <td>RUNNER</td>\n",
       "      <td>25-34</td>\n",
       "      <td>...</td>\n",
       "      <td>Stretches When You Sweat</td>\n",
       "      <td>2018-10-08</td>\n",
       "      <td>I bought this shirt for my husband to run the Chicago Marathon. Upon startin...</td>\n",
       "      <td>2018-10-09 00:00:00</td>\n",
       "      <td>Hi Jkd123,  Thanks for reaching out and providing this feedback for us. I co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>269</td>\n",
       "      <td>1</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Metal Vent Tech Short Sleeve</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Short Sleeves</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>SLASH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>OVERLAND PARK, KS, USA</td>\n",
       "      <td>SWEATY GENERALIST</td>\n",
       "      <td>45-54</td>\n",
       "      <td>...</td>\n",
       "      <td>Love Lulu</td>\n",
       "      <td>2018-10-08</td>\n",
       "      <td>I have several shirts and shorts I have purchased from Lululemon. Hands down...</td>\n",
       "      <td>No Response</td>\n",
       "      <td>No Response</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Metal Vent Tech Short Sleeve</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Short Sleeves</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>BRANDONM19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HUTCHINSON, KS</td>\n",
       "      <td>SWEATY GENERALIST</td>\n",
       "      <td>18-24</td>\n",
       "      <td>...</td>\n",
       "      <td>Sweat wicking shirt</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>Great for workouts.</td>\n",
       "      <td>No Response</td>\n",
       "      <td>No Response</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_name product_category product_category_type  \\\n",
       "0  Metal Vent Tech Short Sleeve             Tops         Short Sleeves   \n",
       "1  Metal Vent Tech Short Sleeve             Tops         Short Sleeves   \n",
       "2  Metal Vent Tech Short Sleeve             Tops         Short Sleeves   \n",
       "3  Metal Vent Tech Short Sleeve             Tops         Short Sleeves   \n",
       "4  Metal Vent Tech Short Sleeve             Tops         Short Sleeves   \n",
       "\n",
       "   product_price  product_average_rating customer_username  review_rating  \\\n",
       "0           68.0                     2.9             NYR26            5.0   \n",
       "1           68.0                     2.9             MJB23            1.0   \n",
       "2           68.0                     2.9            JKD123            1.0   \n",
       "3           68.0                     2.9             SLASH            5.0   \n",
       "4           68.0                     2.9        BRANDONM19            4.0   \n",
       "\n",
       "        customer_location customer_athlete_type customer_age_range  \\\n",
       "0            STAMFORD, CT     SWEATY GENERALIST              18-24   \n",
       "1        CHICAGO, IL, USA     SWEATY GENERALIST              18-24   \n",
       "2        CHICAGO, IL, USA                RUNNER              25-34   \n",
       "3  OVERLAND PARK, KS, USA     SWEATY GENERALIST              45-54   \n",
       "4          HUTCHINSON, KS     SWEATY GENERALIST              18-24   \n",
       "\n",
       "         ...                     review_title review_date  \\\n",
       "0        ...                  The best tshirt  2018-10-12   \n",
       "1        ...                Very Poor Quality  2018-10-11   \n",
       "2        ...         Stretches When You Sweat  2018-10-08   \n",
       "3        ...                        Love Lulu  2018-10-08   \n",
       "4        ...              Sweat wicking shirt  2018-10-03   \n",
       "\n",
       "                                                                       review_text  \\\n",
       "0  These are the most comfortable T-shirts. Wish you guys would make more color...   \n",
       "1  I purchased this Short Sleeve expecting it to be just like all the other one...   \n",
       "2  I bought this shirt for my husband to run the Chicago Marathon. Upon startin...   \n",
       "3  I have several shirts and shorts I have purchased from Lululemon. Hands down...   \n",
       "4                                                              Great for workouts.   \n",
       "\n",
       "         response_date  \\\n",
       "0          No Response   \n",
       "1  2018-10-11 00:00:00   \n",
       "2  2018-10-09 00:00:00   \n",
       "3          No Response   \n",
       "4          No Response   \n",
       "\n",
       "                                                                     response_text  \\\n",
       "0                                                                      No Response   \n",
       "1  Dear mjb23,  Thanks for reaching out and providing this feedback for us. We ...   \n",
       "2  Hi Jkd123,  Thanks for reaching out and providing this feedback for us. I co...   \n",
       "3                                                                      No Response   \n",
       "4                                                                      No Response   \n",
       "\n",
       "  review_helpful_count review_nothelpful_count review_length review_response  \\\n",
       "0                    0                       0           150               0   \n",
       "1                    0                       0           567               1   \n",
       "2                    0                       0           269               1   \n",
       "3                    0                       0           170               0   \n",
       "4                    0                       0            19               0   \n",
       "\n",
       "   customer_country  \n",
       "0               USA  \n",
       "1               USA  \n",
       "2               USA  \n",
       "3               USA  \n",
       "4               USA  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
